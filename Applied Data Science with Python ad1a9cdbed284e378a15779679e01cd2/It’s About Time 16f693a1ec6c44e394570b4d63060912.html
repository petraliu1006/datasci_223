<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>It’s About Time</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	padding-inline-start: 0;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.page-description {
    margin-bottom: 2em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.highlight-gray_background {
	background: rgba(241, 241, 239, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.highlight-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.block-color-gray_background {
	background: rgba(241, 241, 239, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.block-color-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-uiBlue { background-color: rgba(35, 131, 226, .07); }
.select-value-color-pink { background-color: rgba(245, 224, 233, 1); }
.select-value-color-purple { background-color: rgba(232, 222, 238, 1); }
.select-value-color-green { background-color: rgba(219, 237, 219, 1); }
.select-value-color-gray { background-color: rgba(227, 226, 224, 1); }
.select-value-color-translucentGray { background-color: rgba(255, 255, 255, 0.0375); }
.select-value-color-orange { background-color: rgba(250, 222, 201, 1); }
.select-value-color-brown { background-color: rgba(238, 224, 218, 1); }
.select-value-color-red { background-color: rgba(255, 226, 221, 1); }
.select-value-color-yellow { background-color: rgba(253, 236, 200, 1); }
.select-value-color-blue { background-color: rgba(211, 229, 239, 1); }
.select-value-color-pageGlass { background-color: undefined; }
.select-value-color-washGlass { background-color: undefined; }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="16f693a1-ec6c-44e3-9457-0b4d63060912" class="page sans"><header><div class="page-header-icon undefined"><span class="icon">⏱️</span></div><h1 class="page-title">It’s About Time</h1><p class="page-description"></p></header><div class="page-body"><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="93dd96a1-7cd7-424e-b29e-0b9d73a40451"><div style="font-size:1.5em"><span class="icon">💡</span></div><div style="width:100%"><strong>Note:</strong> Always use UTC or epoch (“unix time”) for timestamps to avoid complications with time zones, daylight savings, and leap years/seconds</div></figure><h1 id="fefd6eb4-8c90-4fa3-a36d-ce5b325d17fb" class=""><strong>Fundamentals</strong></h1><p id="a8686a42-4cee-4ed1-a56d-66e42b77cf73" class="">Time series data is characterized by sequential measurements over intervals. Understanding its components—trend, seasonality, and noise—is crucial for effective analysis.</p><h2 id="e4919804-e2c7-4060-8bf0-3a47597f0a46" class=""><strong>Key Concepts:</strong></h2><ul id="cbd67b06-5e99-4319-9fa2-502519a173f0" class="bulleted-list"><li style="list-style-type:disc"><strong>Trend</strong>: The underlying pattern in the data over time</li></ul><ul id="833ee658-4514-47d1-95be-a194fe7e6f4a" class="bulleted-list"><li style="list-style-type:disc"><strong>Seasonality</strong>: Regular variations tied to time intervals, such as days, months, or seasons</li></ul><ul id="95eba79a-fb10-4f35-850e-1bcb53dd97a7" class="bulleted-list"><li style="list-style-type:disc"><strong>Noise</strong>: Random fluctuations that obscure the underlying pattern</li></ul><h2 id="1283bc58-0e06-4f66-be70-a6981f0858d5" class=""><strong>Challenges in Time Series Analysis</strong></h2><ul id="b99838c8-def0-4486-9e9d-1199e1050c68" class="bulleted-list"><li style="list-style-type:disc"><strong>Handling Missing Values</strong>: Time series data often comes with gaps that need to be addressed carefully.</li></ul><ul id="82a951bc-734b-4f65-8830-5493a33a11cd" class="bulleted-list"><li style="list-style-type:disc"><strong>Stationarity</strong>: Many time series methods assume the data is stationary. Transformations or differencing may be required</li></ul><ul id="a089d7b0-c7e1-40a8-85d8-1b0c90fad239" class="bulleted-list"><li style="list-style-type:disc"><strong>Choosing the Right Model</strong>: No one-size-fits-all. Model selection depends on the specific characteristics of the data</li></ul><ul id="0f2b802d-308d-4b67-82a8-20dff478f406" class="bulleted-list"><li style="list-style-type:disc"><strong>Model Complexity and Overfitting</strong>: As models become more sophisticated to capture complex patterns, there&#x27;s a risk of overfitting to historical data, making it less generalizable to future data</li></ul><h2 id="bfeb518c-72a6-41fc-a97c-00a5b2055931" class="">Applications</h2><ul id="20a832b2-0860-492b-9770-f16fc8b7aa16" class="bulleted-list"><li style="list-style-type:disc"><strong>Patient Monitoring: </strong>Analyzing time series data from patient monitoring devices can help in early detection of deteriorating health conditions</li></ul><ul id="bc1aa774-3b3e-4983-b0e1-1fcab2e3ac3c" class="bulleted-list"><li style="list-style-type:disc"><strong>Resource Allocation</strong>: Time series analysis can predict hospital admissions or disease outbreaks, aiding in efficient resource allocation and preparedness</li></ul><ul id="ac7cd133-dac9-45eb-8315-5d46d33044a7" class="bulleted-list"><li style="list-style-type:disc"><strong>Disease Trend Analysis: </strong>Studying the incidence and prevalence of diseases over time can inform public health strategies and interventions</li></ul><ul id="b17be267-080f-4d83-92ba-7ff9d30aa9be" class="bulleted-list"><li style="list-style-type:disc"><strong>Treatment Effectiveness Over Time: </strong>Longitudinal data can shed light on how patients respond to treatments across different time frames</li></ul><h1 id="7fbe9a63-a713-4cb7-9404-c04b7f9caadb" class="">ML/Stats Methods</h1><h2 id="8ddb24ec-b213-496d-ac9f-25d1f25a1bf4" class="">Summary</h2><ul id="88a42c20-757c-419e-8697-1253776a6c48" class="bulleted-list"><li style="list-style-type:disc"><strong>Cross-Validation for Time-Series (TimeSeriesSplit)</strong>: For cross-validation in time series, respecting the temporal order of data.</li></ul><ul id="984f5d10-f9ab-4269-a47e-e5f8484eac6a" class="bulleted-list"><li style="list-style-type:disc"><strong>ARIMA</strong>: Suitable for forecasting when data shows trends or seasonality, requiring parameter tuning (p, d, q).</li></ul><ul id="660624b2-e402-4fc2-b465-7839dffb512e" class="bulleted-list"><li style="list-style-type:disc"><strong>Cox Regression</strong>: Used in survival analysis, modeling the time until an event occurs, factoring in various covariates.</li></ul><ul id="49803221-36e8-4e6b-9973-770e6d6e282c" class="bulleted-list"><li style="list-style-type:disc"><strong>Kaplan-Meier</strong>: Analyzes duration until events, useful in diverse fields like medicine and engineering.</li></ul><ul id="8d365fef-1b2c-4721-9e18-5bb569fbe0f8" class="bulleted-list"><li style="list-style-type:disc"><strong>Advanced Topics:</strong><ul id="cb6e8409-5124-43ca-a4c8-ec92f16b5db9" class="bulleted-list"><li style="list-style-type:circle"><strong>Vector Autoregression</strong>: Captures interdependencies in multivariate time series data.</li></ul><ul id="2a6692e9-e7f7-4a12-88b8-6b4466e614cf" class="bulleted-list"><li style="list-style-type:circle"><strong>Seasonal Decomposition</strong>: Breaks down time series into trend, seasonal, and residual components.</li></ul><ul id="9eaaf4fc-b160-4160-861c-930e076acebb" class="bulleted-list"><li style="list-style-type:circle"><strong>Dynamic Time Warping</strong>: Measures similarity between two temporal sequences, useful for varying speeds.</li></ul><ul id="1e2cedcc-516e-4323-89a1-d0c7c01eb315" class="bulleted-list"><li style="list-style-type:circle"><strong>State Space Models and Kalman Filters</strong>: For modeling observed and unobserved variables in time series, with Kalman Filters estimating hidden states.</li></ul><ul id="7b3c9151-12f4-433f-87bb-cb17fad7c025" class="bulleted-list"><li style="list-style-type:circle"><strong>Generalized Additive Models</strong>: Flexible approach for non-linear time series data relationships.</li></ul><ul id="111f552b-c019-4c99-a17b-71aad22ace52" class="bulleted-list"><li style="list-style-type:circle"><strong>Prophet</strong>: Forecasts time series data with trends and seasonality, fitting yearly, weekly, and daily patterns.</li></ul></li></ul><h2 id="6a5c0a8a-3b08-4999-9bf6-da99cc39218c" class=""><strong>Cross-Validation for Time Series</strong></h2><p id="140344e3-a222-4e71-8419-6ea1cad8d019" class="">Unlike traditional cross-validation, time series cross-validation involves rolling or expanding windows due to the ordered nature of the data.</p><figure id="d3aeea74-0dca-4d41-b39b-5deeb2f5a58a" class="image"><a href="It%E2%80%99s%20About%20Time%2016f693a1ec6c44e394570b4d63060912/Untitled.png"><img style="width:602px" src="It%E2%80%99s%20About%20Time%2016f693a1ec6c44e394570b4d63060912/Untitled.png"/></a></figure><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="42db1e6d-a3d8-4dc1-aeed-3322df5b3f41" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">from sklearn.model_selection import TimeSeriesSplit

tscv = TimeSeriesSplit()
for train_index, test_index in tscv.split(X):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]</code></pre><h2 id="9483a5aa-e174-4189-a780-314d59c1cb68" class="">ARIMA (AutoRegressive Integrated Moving Average)</h2><figure id="bd02aecf-4da4-4441-b1b7-0737e84e2db9" class="image"><a href="It%E2%80%99s%20About%20Time%2016f693a1ec6c44e394570b4d63060912/Untitled%201.png"><img style="width:776px" src="It%E2%80%99s%20About%20Time%2016f693a1ec6c44e394570b4d63060912/Untitled%201.png"/></a></figure><p id="c28796fc-902e-4c1e-9c62-d61171cfdf81" class="">ARIMA is a popular statistical method for time series forecasting that models the data as a linear combination of its past values (autoregressive part), differences of past values (integrated part), and past forecast errors (moving average part). It&#x27;s effective for data with trends and/or seasonality.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="eb39c22d-20b8-45e4-9c43-1b5977c1125a" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">from statsmodels.tsa.arima.model import ARIMA
import pandas as pd

# Load your time series data
# data = pd.read_csv(&#x27;your_time_series.csv&#x27;)

# Initialize and fit the ARIMA model
# The order (p,d,q) needs to be determined based on your data
model = ARIMA(data, order=(p, d, q))
model_fit = model.fit()

# Forecast future values
forecast = model_fit.forecast(steps=5)
</code></pre><h3 id="848a57e8-9a1d-4a66-8847-2281886c081e" class=""><strong>Parameters</strong></h3><ul id="409ec10c-704b-458d-91d6-2546416c8991" class="bulleted-list"><li style="list-style-type:disc"><code>p</code>: Autoregressive order, number of lag observations included in the model, also known as the lag order</li></ul><ul id="90c728ef-fddd-4ad5-b809-2e1b8712b4a0" class="bulleted-list"><li style="list-style-type:disc"><code>d</code>: Differencing order; number of times the raw observations are differenced, also referred to as the degree of differencing</li></ul><ul id="2ab06a7f-5b5f-4bdf-abde-c9c475d390d9" class="bulleted-list"><li style="list-style-type:disc"><code>q</code>: Moving average order, specifies the size of the moving average window, or the order of the moving average component of the model</li></ul><h2 id="67e460c0-fe77-4a26-8d98-26ec264b8455" class="">Cox Regression</h2><figure id="a5c61f35-a749-45b4-bc75-e215e5425616" class="image"><a href="It%E2%80%99s%20About%20Time%2016f693a1ec6c44e394570b4d63060912/Untitled%202.png"><img style="width:512px" src="It%E2%80%99s%20About%20Time%2016f693a1ec6c44e394570b4d63060912/Untitled%202.png"/></a></figure><p id="2bb977e5-8f6f-4d7b-abea-9b5f9932c27d" class="">Cox Regression, also known as the Cox Proportional Hazards Model, is used in survival analysis to model the time until an event occurs, considering the impact of various covariates. It&#x27;s a semi-parametric model that estimates the hazard (or risk) of the event occurring at a certain time.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="4e850cfc-d2f8-43d0-8066-d2dba0a05ceb" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">from lifelines import CoxPHFitter

# Assuming `df` is your DataFrame with &#x27;duration&#x27; and &#x27;event&#x27; columns
# and additional columns for covariates
# coxph = CoxPHFitter()
# coxph.fit(df, duration_col=&#x27;duration&#x27;, event_col=&#x27;event&#x27;)

# Predicting the hazard
# predictions = coxph.predict_survival_function(df)</code></pre><h3 id="ee246ab8-0177-460d-b4f4-29a271621a4f" class=""><strong>Parameters</strong></h3><ul id="17d8874b-bf08-4094-9f35-5b2f0f081c22" class="bulleted-list"><li style="list-style-type:disc"><code>duration_col</code>: Column in DataFrame that contains the duration until the event or censoring</li></ul><ul id="6023db55-d255-4fbc-a10a-37a0051728d7" class="bulleted-list"><li style="list-style-type:disc"><code>event_col</code>: Column in DataFrame that indicates if the event of interest occurred</li></ul><h2 id="eaf5b732-72bb-49f6-a182-30165a5939f4" class="">Survival Analysis</h2><figure id="061c77df-00ea-4726-8525-325e760698a1" class="image"><a href="It%E2%80%99s%20About%20Time%2016f693a1ec6c44e394570b4d63060912/Untitled%203.png"><img style="width:847px" src="It%E2%80%99s%20About%20Time%2016f693a1ec6c44e394570b4d63060912/Untitled%203.png"/></a></figure><p id="8971e397-cbcf-46ea-b157-e8f81f139ff0" class="">Kaplan-Meier survival analysis involves statistical methods for analyzing the expected duration until one or more events happen, like death in biological organisms and failure in mechanical systems. It&#x27;s used in medicine, biology, engineering, economics, and many other fields.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="728486f1-3a8a-4e46-896c-fca465250461" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">from lifelines import KaplanMeierFitter

# Assuming `df` is your DataFrame with &#x27;duration&#x27; and &#x27;event&#x27; columns
kmf = KaplanMeierFitter()
kmf.fit(durations=df[&quot;duration&quot;], event_observed=df[&quot;event&quot;])

# Plotting the survival function
kmf.plot_survival_function()
</code></pre><h3 id="dc4d4549-a6fc-4d3e-9080-e28a33ee217e" class=""><strong>Parameters</strong></h3><ul id="d19f674d-3354-478b-833a-bab9542bb337" class="bulleted-list"><li style="list-style-type:disc"><code>durations</code>: Duration until an event or censoring</li></ul><ul id="9a9e88e8-3984-4620-9272-7aa04950f118" class="bulleted-list"><li style="list-style-type:disc"><code>event_observed</code>: Whether the event of interest occurred</li></ul><h2 id="d5a6327b-c3b8-4cc8-ab1c-83888a358777" class="">Advanced Topics</h2><h3 id="c98766b0-794d-4765-9676-d059308c13b1" class=""><strong>Vector Autoregression</strong></h3><p id="27e70148-a5f7-4965-8eb9-a81cf8730d3d" class="">A multivariate statistical model used to capture the linear interdependencies among multiple time series. Used for multivariate time series.</p><figure id="4451d405-508e-4fcf-9bf5-ec9d8ad8bcc9"><a href="https://www.analyticsvidhya.com/blog/2021/08/vector-autoregressive-model-in-python/" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">Developing Vector AutoRegressive Model in Python!</div><div class="bookmark-description">Vector AutoRegressive (VAR) is a multivariate forecasting algorithm that is used when two or more time series influence each other.</div></div><div class="bookmark-href"><img src="https://www.analyticsvidhya.com/wp-content/uploads/2015/02/logo_square_v2.jpg" class="icon bookmark-icon"/>https://www.analyticsvidhya.com/blog/2021/08/vector-autoregressive-model-in-python/</div></div><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/01/time-series-.jpg" class="bookmark-image"/></a></figure><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="830501fa-8643-4d39-91f1-8d4e939ce23b" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">from statsmodels.tsa.api import VAR

model = VAR(endog=df)
model_fit = model.fit(maxlags=15, ic=&#x27;aic&#x27;)</code></pre><h3 id="863e3bc6-c065-44f0-a38b-6533b458d938" class=""><strong>Seasonal Decomposition</strong></h3><figure id="6596b055-b8b3-4f4c-8139-bc09c87f26b3" class="image"><a href="It%E2%80%99s%20About%20Time%2016f693a1ec6c44e394570b4d63060912/Untitled%204.png"><img style="width:432px" src="It%E2%80%99s%20About%20Time%2016f693a1ec6c44e394570b4d63060912/Untitled%204.png"/></a></figure><p id="42e5c4f0-124f-4ec7-b796-097164518e8d" class="">Decomposing a time series means breaking it down into its constituent components: trend, seasonal, and residual.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="66970747-5cd4-4740-8c33-6b3e820f6049" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">from statsmodels.tsa.seasonal import seasonal_decompose

# Perform decomposition
result = seasonal_decompose(data, model=&#x27;additive&#x27;, period=12)

# Plot the decomposed components
result.plot()
</code></pre><h3 id="6b5da40c-3e73-4b00-8ae0-ec02d035df28" class=""><strong>Dynamic Time Warping</strong></h3><figure id="536b316d-87e9-4ce6-851c-6dd8f9b3c1d4" class="image"><a href="It%E2%80%99s%20About%20Time%2016f693a1ec6c44e394570b4d63060912/IMG_0095.webp"><img style="width:707.9988403320312px" src="It%E2%80%99s%20About%20Time%2016f693a1ec6c44e394570b4d63060912/IMG_0095.webp"/></a></figure><p id="36cf850f-b2da-4f4a-af06-964f8f22b762" class="">An algorithm for measuring similarity between two temporal sequences which may vary in speed.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1e1ab835-b731-41eb-9c6e-78880741b5bb" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">from dtaidistance import dtw

distance = dtw.distance(sequence1, sequence2)</code></pre><h3 id="32273274-282a-448a-9c6c-2a07a6d4a9df" class=""><strong>State Space Models and Kalman Filters</strong></h3><p id="e21900de-9633-403c-bd4b-9e836aac821f" class="">A framework for modeling time series data that allows incorporating both observed and unobserved variables, with Kalman Filters providing a way to infer hidden states.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="a032531a-5f8a-488a-8d55-a3351db5d9e1" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">from pykalman import KalmanFilter

kf = KalmanFilter(initial_state_mean=0, n_dim_obs=2)
(filtered_state_means, filtered_state_covariances) = kf.filter(data)</code></pre><h3 id="638582f9-b238-473a-9a24-ea8b8c17a4e8" class=""><strong>Generalized Additive Models for Time Series</strong></h3><p id="e294e372-a2fa-4756-9316-7725811e2080" class="">Flexible models that allow the data to determine the shape of the relationship between variables, useful for non-linear time series data.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="bbe5e43e-2317-48e4-a6cc-b03e1e951fbf" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">from pygam import LinearGAM, s

gam = LinearGAM(s(0) + s(1)).fit(X, y)
gam.predict(X_new)</code></pre><h3 id="71477525-f148-4394-8cad-ad09234b1530" class=""><strong>Prophet by Facebook</strong></h3><figure id="21968ff4-4f82-466c-a657-da8d478a6906" class="image"><a href="It%E2%80%99s%20About%20Time%2016f693a1ec6c44e394570b4d63060912/Untitled%205.png"><img style="width:700px" src="It%E2%80%99s%20About%20Time%2016f693a1ec6c44e394570b4d63060912/Untitled%205.png"/></a></figure><p id="c75a65b8-3c1d-4eb3-a5a3-8b9039eddc2a" class="">Prophet is a tool for forecasting time series data based on an additive model where non-linear trends fit with yearly, weekly, and daily seasonality.</p><ul id="0aa982d6-01e4-4c61-96cf-0881eb99db91" class="bulleted-list"><li style="list-style-type:disc"><a href="https://polzinben.github.io/Time-Series-Forecasting/"><strong>Time Series Forecasting with TensorFlow, ARIMA, and PROPHET</strong></a></li></ul><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="292ed836-f37e-4563-8bc3-f65eb8dc2eef" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">from fbprophet import Prophet

# Initialize the Prophet model
model = Prophet()

# Fit the model
model.fit(df)

# Make a future dataframe and forecast
future = model.make_future_dataframe(periods=365)
forecast = model.predict(future)</code></pre><h1 id="83874772-55bd-4ca2-b9df-6e7dfc3caac1" class="">Recurrent Neural Networks</h1><p id="a301a943-79e5-4f2c-b19c-a2de37b4b9a6" class="">Recurrent Neural Networks (RNNs) are a class of neural networks designed to recognize patterns in sequences of data, such as time series, genomes, handwriting, or spoken words. Unlike traditional neural networks, RNNs use their internal state (memory) to process variable length sequences of inputs.</p><figure id="71d6a982-3cbb-4a5d-a880-2b6e1b7c92eb" class="image"><a href="It%E2%80%99s%20About%20Time%2016f693a1ec6c44e394570b4d63060912/Untitled%206.png"><img style="width:301px" src="It%E2%80%99s%20About%20Time%2016f693a1ec6c44e394570b4d63060912/Untitled%206.png"/></a></figure><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="b2460310-e79c-4b49-a547-8f4d63d1d895" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">from keras.models import Sequential
from keras.layers import SimpleRNN, Dense

# Define the model
model = Sequential()
model.add(SimpleRNN(units=50, activation=&#x27;tanh&#x27;, input_shape=(None, 1)))
model.add(Dense(units=1, activation=&#x27;linear&#x27;))

# Compile the model
model.compile(optimizer=&#x27;adam&#x27;, loss=&#x27;mean_squared_error&#x27;)</code></pre><h3 id="089f8b38-9e69-4127-ba4b-eeb9be975d63" class="">Examples</h3><ul id="d8fe10ab-b5e6-4ad8-a87b-054ea41ea793" class="bulleted-list"><li style="list-style-type:disc"><strong>Forecasting:</strong> e.g., weather</li></ul><ul id="97b33791-5002-47d6-a4e3-0ea74182fc62" class="bulleted-list"><li style="list-style-type:disc"><strong>Text Generation:</strong> generating text character by character or word by word</li></ul><ul id="5fd1878c-04a8-4cc4-95a5-39eea47ff50f" class="bulleted-list"><li style="list-style-type:disc"><strong>Speech Recognition:</strong> transcribing spoken words into text</li></ul><h2 id="88bb45c9-9209-4b54-b833-dc193141f055" class=""><strong>Long Short-Term Memory (LSTM) Networks</strong></h2><p id="616be132-b52c-4a7d-b560-c60a697b2c6b" class="">LSTMs are a type of RNN designed to remember information for long periods, making them ideal for time series data.</p><figure id="f6f02097-1352-4902-b70c-3116168580dd"><a href="https://www.analyticsvidhya.com/blog/2022/01/the-complete-lstm-tutorial-with-implementation/" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">The Complete LSTM Tutorial With Implementation</div><div class="bookmark-description">LSTMs are a stack of neural networks composed of linear layers; weights and biases. We will study the LSTM tutorial with its implementation.</div></div><div class="bookmark-href"><img src="https://www.analyticsvidhya.com/wp-content/uploads/2015/02/logo_square_v2.jpg" class="icon bookmark-icon"/>https://www.analyticsvidhya.com/blog/2022/01/the-complete-lstm-tutorial-with-implementation/</div></div><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2021/01/92270power_of_lstms_2.jpg" class="bookmark-image"/></a></figure><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1963d0c2-4041-423d-a1e5-dc0d57d09e09" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">from keras.models import Sequential
from keras.layers import LSTM, Dense

# Define the model
model = Sequential()
model.add(LSTM(units=50, activation=&#x27;tanh&#x27;, input_shape=(time_steps, features)))
model.add(Dense(units=1, activation=&#x27;linear&#x27;))

# Compile the model
model.compile(optimizer=&#x27;adam&#x27;, loss=&#x27;mean_squared_error&#x27;)
</code></pre><h1 id="5c6588a3-29c0-441e-93eb-a1b78e2b5d61" class="">LLM’s (Large Language Models)</h1><figure id="2117ee66-2fbe-41f7-9ae9-ffa8b207a505"><a href="https://huggingface.co/papers/2403.07815" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">Paper page - Chronos: Learning the Language of Time Series</div><div class="bookmark-description">Join the discussion on this paper page</div></div><div class="bookmark-href"><img src="https://huggingface.co/favicon.ico" class="icon bookmark-icon"/>https://huggingface.co/papers/2403.07815</div></div><img src="https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.07815/gradient.png" class="bookmark-image"/></a></figure><h2 id="0cf25638-d751-4b24-85e0-8a258739af0c" class="">Example: Patient Trajectory Encoding</h2><p id="dc9079fd-5b8b-4d3d-94ef-63ef579ff04d" class="">In the context of healthcare, LLMs can be adapted to encode patient trajectories instead of words. This involves training the model on patient data to predict future health events or outcomes based on past medical history, similar to how a language model predicts the next word in a sentence.</p><ul id="59719936-0923-4de6-8972-4973bbc3248c" class="bulleted-list"><li style="list-style-type:disc"><a href="https://www.unlearn.ai/"><strong>Unlearn.ai</strong></a><strong>:</strong> A platform that creates &quot;digital twins&quot; of patients, which are computational models predicting individual patient trajectories.</li></ul><p id="3c1b295f-a338-4806-938f-7ccd5b66be4a" class="">This approach allows for personalized medicine by simulating how different treatments might affect a patient over time. The founder of <a href="http://unlearn.ai/">Unlearn.ai</a> will be speaking in a seminar early May, potentially providing more insights into the application of LLMs in healthcare.</p><figure id="84735afb-3905-4d2d-812a-6253188fc429"><a href="https://www.nature.com/articles/s41746-023-00879-8" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title"></div></div><div class="bookmark-href">https://www.nature.com/articles/s41746-023-00879-8</div></div></a></figure><figure id="3b8b92f1-bd36-42d4-afd2-87f368d4839e"><a href="https://www.medrxiv.org/content/10.1101/2024.02.29.24303512v1.full" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">A Transformer-Based Model for Zero-Shot Health Trajectory Prediction</div><div class="bookmark-description">Integrating modern machine learning and clinical decision-making has great promise for mitigating healthcare’s increasing cost and complexity. We introduce the Enhanced Transformer for Health Outcome Simulation (ETHOS), a novel application of the transformer deep-learning architecture for analyzing high-dimensional, heterogeneous, and episodic health data. ETHOS is trained using Patient Health Timelines (PHTs)—detailed, tokenized records of health events—to predict future health trajectories, leveraging a zero-shot learning approach.  ETHOS represents a significant advancement in foundation model development for healthcare analytics, eliminating the need for labeled data and model fine-tuning. Its ability to simulate various treatment pathways and consider patient-specific factors positions ETHOS as a tool for care optimization and addressing biases in healthcare delivery. Future developments will expand ETHOS’ capabilities to incorporate a wider range of data types and data sources. Our work demonstrates a pathway toward accelerated AI development and deployment in healthcare.  ### Competing Interest Statement  Yugang Jia is currently also affiliated with Verily life science, SSF, CA.  ### Funding Statement  This work was supported in part by National Institutes of Health (NIH) grant number HL159183.  ### Author Declarations  I confirm all relevant ethical guidelines have been followed, and any necessary IRB and/or ethics committee approvals have been obtained.  Yes  The details of the IRB/oversight body that provided approval or exemption for the research described are given below:  https://physionet.org/content/mimiciv/2.2/  I confirm that all necessary patient/participant consent has been obtained and the appropriate institutional forms have been archived, and that any patient/participant/sample identifiers included were not known to anyone (e.g., hospital staff, patients or participants themselves) outside the research group so cannot be used to identify individuals.  Yes  I understand that all clinical trials and any other prospective interventional studies must be registered with an ICMJE-approved registry, such as ClinicalTrials.gov. I confirm that any such study reported in the manuscript has been registered and the trial registration ID is provided (note: if posting a prospective study registered retrospectively, please provide a statement in the trial ID field explaining why the study was not registered in advance).  Yes  I have followed all appropriate research reporting guidelines, such as any relevant EQUATOR Network research reporting checklist(s) and other pertinent material, if applicable.  Yes  All data produced in the present study are available upon reasonable request to the authors</div></div><div class="bookmark-href"><img src="https://www.medrxiv.org/sites/default/files/images/favicon.ico" class="icon bookmark-icon"/>https://www.medrxiv.org/content/10.1101/2024.02.29.24303512v1.full</div></div><img src="https://www.medrxiv.org/sites/default/files/images/medrxiv_logo_homepage7-5-small-test-up.png" class="bookmark-image"/></a></figure><figure id="897074c2-f10c-4d60-84fd-e04ac2221a37"><a href="https://www.nature.com/articles/s41746-022-00742-2" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title"></div></div><div class="bookmark-href">https://www.nature.com/articles/s41746-022-00742-2</div></div></a></figure><details open=""><summary style="font-weight:600;font-size:1.875em;line-height:1.3;margin:0">Practice: Smartwatch Gestures</summary><div class="indented"><p id="a2607576-b1f4-4fdb-87b8-add2f38ab503" class="">The &quot;smartwatch_gestures&quot; dataset consists of sensor data collected from smartwatches, capturing various gestures. </p><p id="3e8c9274-c870-4fcc-bd2f-55f36a85e0c9" class="">We can perform exploratory data analysis (EDA) to understand the characteristics of these gestures, including the distribution of gesture classes, basic statistics of sensor readings, and visualization of gesture patterns.</p><h2 id="bf80a24a-a5d9-4a0b-8dba-04705108817b" class="">Load the Dataset</h2><p id="c802820b-a626-4645-a2f6-71fe96943dfb" class="">First, we need to load the dataset. If you&#x27;re using TensorFlow Datasets (<code>tfds</code>), you can load the dataset as follows:</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="7fb226ce-24d8-48ef-9dcc-4cbbae96b5a2" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">import tensorflow_datasets as tfds

# Load the SmartWatch Gestures Dataset
ds, ds_info = tfds.load(&#x27;smartwatch_gestures&#x27;, with_info=True, as_supervised=False)

# Get the training dataset
train_ds = ds[&#x27;train&#x27;]
</code></pre><h2 id="691e37ac-73b1-4b6a-a779-651e47499aaa" class="">Explore the Dataset</h2><p id="8300e7f1-db59-443a-8f36-352d731fefc6" class="">We&#x27;ll explore the dataset to understand the structure of the data, including the features available (such as accelerometer and gyroscope sensor readings) and the target variable (gesture labels).</p><h3 id="77a5a132-da18-4ea7-86f2-daad41285606" class="">Data Exploration</h3><p id="4eea8ecf-fb35-4f25-97d8-5fa31affe79e" class="">Let&#x27;s plot acceleration patterns for a specific gesture performed by different participants. This will help us see the variance in how different people perform the same gesture.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1fbc567e-819d-4aac-b0f3-c34924a25b7a" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">import matplotlib.pyplot as plt

def plot_accelerations(features, gesture_id, participant_id):
    # Extract acceleration data for the specified gesture and participant
    accel_x = []
    accel_y = []
    accel_z = []

    for row in features:
        if row[&#x27;gesture&#x27;].numpy() == gesture_id and row[&#x27;participant&#x27;].numpy() == participant_id:
            for feature in row[&#x27;features&#x27;]:
                accel_x.append(feature[&#x27;accel_x&#x27;])
                accel_y.append(feature[&#x27;accel_y&#x27;])
                accel_z.append(feature[&#x27;accel_z&#x27;])

    # Plot the acceleration data
    plt.figure(figsize=(15, 5))
    plt.plot(accel_x, label=&#x27;Accel X&#x27;)
    plt.plot(accel_y, label=&#x27;Accel Y&#x27;)
    plt.plot(accel_z, label=&#x27;Accel Z&#x27;)
    plt.title(f&#x27;Acceleration Patterns for Gesture {gesture_id}, Participant {participant_id}&#x27;)
    plt.xlabel(&#x27;Sample&#x27;)
    plt.ylabel(&#x27;Acceleration&#x27;)
    plt.legend()
    plt.show()

# Example: Plot accelerations for gesture 0 performed by participant 1
plot_accelerations(train_ds, gesture_id=0, participant_id=1)</code></pre><h3 id="d63d1e8a-25fc-4fed-89af-e764895558dc" class="">Convert to Pandas DataFrame for Easier Analysis</h3><p id="9e940d09-68f4-4490-86dc-c3397d132e02" class="">For easier analysis, we&#x27;ll convert the TensorFlow dataset to a Pandas DataFrame. This step might involve batch processing and concatenation since TensorFlow datasets are typically in a format optimized for machine learning rather than data analysis.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="e7d9cd38-e543-4e91-b862-67a52acf344e" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">import pandas as pd
import tensorflow as tf

# Load the dataset
train_ds = tfds.load(&#x27;smartwatch_gestures&#x27;, split=&#x27;train&#x27;)

# Initialize lists to hold data
attempt, accel_x, accel_y, accel_z, time_event, time_millis, time_nanos, gesture, participant = ([] for _ in range(9))

# Extract data from the dataset
for row in train_ds:
    attempt.extend(row[&#x27;attempt&#x27;].numpy())
    gesture.extend(row[&#x27;gesture&#x27;].numpy())
    participant.extend(row[&#x27;participant&#x27;].numpy())
    
    # Extract features from each sequence
    for feature in row[&#x27;features&#x27;]:
        accel_x.extend(feature[&#x27;accel_x&#x27;].numpy())
        accel_y.extend(feature[&#x27;accel_y&#x27;].numpy())
        accel_z.extend(feature[&#x27;accel_z&#x27;].numpy())
        time_event.extend(feature[&#x27;time_event&#x27;].numpy())
        time_millis.extend(feature[&#x27;time_millis&#x27;].numpy())
        time_nanos.extend(feature[&#x27;time_nanos&#x27;].numpy())

# Create a DataFrame
df = pd.DataFrame({
    &#x27;Attempt&#x27;: attempt,
    &#x27;Accel_X&#x27;: accel_x,
    &#x27;Accel_Y&#x27;: accel_y,
    &#x27;Accel_Z&#x27;: accel_z,
    &#x27;Time_Event&#x27;: time_event,
    &#x27;Time_Millis&#x27;: time_millis,
    &#x27;Time_Nanos&#x27;: time_nanos,
    &#x27;Gesture&#x27;: gesture,
    &#x27;Participant&#x27;: participant
})

# Display the DataFrame
print(df)
</code></pre><h2 id="ef0c9be9-c503-4493-9051-dc923b222dce" class="">Basic Statistics and Visualization</h2><p id="7d09027f-1d1b-49a2-b3f9-e232726372d9" class="">With the data in a Pandas DataFrame, we can perform basic statistics to understand the sensor data distributions and visualize some gestures.</p><h2 id="73f0bfe4-f830-4874-900a-c7c7f6f92618" class="">Next steps</h2><ol type="1" id="d8a173d3-5229-47f4-b581-e301e55be7e2" class="numbered-list" start="1"><li><strong>Preprocess: </strong>Normalize or standardize the accelerometer data to ensure that each feature contributes equally to the model&#x27;s learning</li></ol><ol type="1" id="c7c60d19-b970-4b1c-a602-e62808689542" class="numbered-list" start="2"><li><strong>Split: </strong>Split the dataset into training and testing sets to evaluate the model&#x27;s performance. You can use <code><strong>train_test_split</strong></code> from <code><strong>sklearn.model_selection</strong></code> for this purpose</li></ol><ol type="1" id="3437bb16-716f-434e-ad6c-405428e479c3" class="numbered-list" start="3"><li><strong>Define a model:</strong> <ul id="00016b14-bc6e-46f2-962a-ac411d572459" class="bulleted-list"><li style="list-style-type:disc"><strong>Machine Learning Models</strong>: You can start with traditional machine learning models such as Random Forest, Support Vector Machines (SVM), or k-Nearest Neighbors (k-NN).</li></ul><ul id="09d3c4f2-26a9-4873-a959-b11773b29ca1" class="bulleted-list"><li style="list-style-type:disc"><strong>Deep Learning Models</strong>: If you have sufficient data, you can use deep learning models such as Convolutional Neural Networks (CNNs) or Recurrent Neural Networks (RNNs) for sequence data.</li></ul></li></ol><ol type="1" id="2c297aab-293f-4be2-bb3a-44e3e48386bb" class="numbered-list" start="4"><li><strong>Train:</strong> Train the selected model on the training dataset. Use the preprocessed accelerometer data as input features and the encoded gesture labels as target variables.</li></ol><ol type="1" id="4b1fdaa8-6514-402c-9f7f-cfca2d370a71" class="numbered-list" start="5"><li><strong>Evaluate: </strong>After training, evaluate the model&#x27;s performance on the testing dataset. Use appropriate evaluation metrics such as accuracy, precision, recall, or F1-score to assess the model&#x27;s performance.</li></ol><h3 id="25164627-6d2e-466f-8a20-fc4d15556950" class="">Example</h3><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="14bacdb4-daa5-4e62-9487-db72901b6035" class="code"><code class="language-Python">from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import xgboost as xgb

# Preprocessing (if needed)
# ...

# Split the data into training and testing sets
X = df[[&#x27;Accel_X&#x27;, &#x27;Accel_Y&#x27;, &#x27;Accel_Z&#x27;]]
y = df[&#x27;Gesture&#x27;]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the RandomForest model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)

# Train
rf_model.fit(X_train, y_train)

# Make predictions
y_pred = rf_model.predict(X_test)

# Evaluate the model
rf_accuracy = accuracy_score(y_test, y_pred)
print(&quot;Random Forest Accuracy:&quot;, rf_accuracy)


# Define the XGBoost model
x_model = xgb.XGBClassifier(objective=&#x27;multi:softmax&#x27;, num_class=len(df[&#x27;Gesture&#x27;].unique()), random_state=42)

# Train
x_model.fit(X_train, y_train)

# Make predictions
y_pred = x_model.predict(X_test)

# Evaluate the model
x_accuracy = accuracy_score(y_test, y_pred)
print(&quot;XGBoost Accuracy:&quot;, x_accuracy)

</code></pre></div></details><details open=""><summary style="font-weight:600;font-size:1.875em;line-height:1.3;margin:0">Practice: Atrial Fibrillation</summary><div class="indented"><h2 id="0e8b71e4-2e82-4b8d-a57c-2464364b5d0b" class="">Download the data</h2><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="749751e7-9702-4630-a695-320e37b8ac52" class="code"><code class="language-Python"># Download the patient files
!wget -r -N -c -np https://physionet.org/files/afpdb/1.0.0/</code></pre><h2 id="60488e59-14ec-4c7b-91e8-5b624116e5cc" class="">List the data files</h2><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="4910a394-2996-429b-87dc-1a7558b36499" class="code"><code class="language-Python">import os

# Base path where the dataset was downloaded
base_path = &#x27;physionet.org/files/afpdb/1.0.0/&#x27;

# Initialize lists to hold file paths for the control and PAF groups
control_files = []
paf_files = []

# Walk through the directory structure
for root, dirs, files in os.walk(base_path):
    for file in files:
        # Check if the file is a .hea file (indicating an ECG record header)
        if file.endswith(&#x27;.hea&#x27;):
            # Construct the full path to the .hea and corresponding .dat file
            header_path = os.path.join(root, file)
            data_path = os.path.join(root, file.replace(&#x27;.hea&#x27;, &#x27;.dat&#x27;))
            
            # Check if the file belongs to the control group (prefix &#x27;n&#x27;) or the PAF group (prefix &#x27;p&#x27;)
            if file.startswith(&#x27;n&#x27;):
                control_files.append((header_path, data_path))
            elif file.startswith(&#x27;p&#x27;):
                paf_files.append((header_path, data_path))</code></pre><h2 id="ca28fd69-1efb-497e-9163-c5dae5ffe930" class="">Load the data</h2><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="71dac0a6-0ba0-4f99-b29a-dc4c2c731358" class="code"><code class="language-Python">import numpy as np

def read_ecg_record(header_path, data_path):
    # Read the header file to get metadata
    with open(header_path, &#x27;r&#x27;) as f:
        header = f.readlines()
    
    # Parse the header for necessary information
    # This is a simplified example; you may need to adjust parsing based on the actual header content
    num_samples = int(header[0].split(&#x27; &#x27;)[3])
    sample_rate = int(header[0].split(&#x27; &#x27;)[2])
    
    # Read the binary ECG data from the .dat file
    with open(data_path, &#x27;rb&#x27;) as f:
        raw_data = np.fromfile(f, dtype=np.int16)
    
    # Convert raw data into a DataFrame
    # This assumes 2-channel ECG data; adjust as necessary
    ecg_data = pd.DataFrame(raw_data.reshape((num_samples, -1)), columns=[&#x27;Channel_1&#x27;, &#x27;Channel_2&#x27;])
    
    return ecg_data

def aggregate_patient_data(patient_files, patient_class):
    all_records = []
    
    for header_path, data_path in patient_files:
        record_df = read_ecg_record(header_path, data_path)
        record_df[&#x27;Patient_Class&#x27;] = patient_class
        all_records.append(record_df)
    
    # Combine all records for this patient into a single DataFrame
    patient_df = pd.concat(all_records).reset_index(drop=True)
    
    return patient_df

# Aggregate data for control and PAF groups
control_data = aggregate_patient_data(control_files, &#x27;Control&#x27;)
paf_data = aggregate_patient_data(paf_files, &#x27;PAF&#x27;)

# Combine data from both groups into a single DataFrame
all_patient_data = pd.concat([control_data, paf_data]).reset_index(drop=True)</code></pre><h2 id="f68353b4-e1bd-46de-a11a-e981b9031766" class="">Basic Statistics</h2><p id="d90eed6b-7ed4-4b7d-b043-a103bf3f2f75" class="">Calculating some basic statistics such as the mean and standard deviation for each ECG channel will give us an idea of the overall signal levels and variability.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="9e3adfe4-c407-477b-aa34-0b65f7cf6ea2" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all"># Calculate basic statistics for each channel and patient class
basic_stats = all_patient_data.groupby(&#x27;Patient_Class&#x27;).agg({
    &#x27;Channel_1&#x27;: [&#x27;mean&#x27;, &#x27;std&#x27;],
    &#x27;Channel_2&#x27;: [&#x27;mean&#x27;, &#x27;std&#x27;]
})

print(basic_stats)
</code></pre><p id="95c3027a-42af-4a93-9ff3-2a5099cda6a2" class="">This code snippet calculates the mean and standard deviation for <code>Channel_1</code> and <code>Channel_2</code> of the ECG signals, grouped by the patient class (Control or PAF). The <code>groupby</code> method is used to separate the data by patient class, and the <code>agg</code> method calculates the specified statistics for each group.</p><h2 id="2cda154a-dea5-46e4-a0b6-f20611fef77d" class="">Visualization</h2><p id="06c803de-8c79-492d-b8fa-dff9cf72b852" class="">Visualizing the ECG signals can provide a more intuitive understanding of the differences between control and PAF patients. We can plot a small segment of the ECG signals for a visual comparison.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1c2a1d9b-daae-49b2-8862-15c4e79bd0e1" class="code"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">import matplotlib.pyplot as plt

def plot_ecg_samples(df, title, num_samples=1000):
    plt.figure(figsize=(15, 5))
    plt.plot(df[&#x27;Channel_1&#x27;].iloc[:num_samples], label=&#x27;Channel 1&#x27;)
    plt.plot(df[&#x27;Channel_2&#x27;].iloc[:num_samples], label=&#x27;Channel 2&#x27;, alpha=0.7)
    plt.title(title)
    plt.xlabel(&#x27;Sample&#x27;)
    plt.ylabel(&#x27;Amplitude&#x27;)
    plt.legend()
    plt.show()

# Select a small sample from each class for plotting
control_sample = control_data.iloc[:1000]
paf_sample = paf_data.iloc[:1000]

# Plot the samples
plot_ecg_samples(control_sample, &#x27;Control Group ECG Sample&#x27;)
plot_ecg_samples(paf_sample, &#x27;PAF Group ECG Sample&#x27;)
</code></pre><p id="834dc770-c572-4a60-a152-8f43308d17d3" class="">The <code>plot_ecg_samples</code> function is defined to plot a specified number of samples from both ECG channels. It then selects a small segment from the control and PAF data and uses this function to create plots for each. This visual comparison can help in identifying any noticeable differences in the ECG signal patterns between the two groups.</p></div></details><p id="651a6d02-d587-44ea-b439-a1441d1a829f" class="">
</p></div></article><span class="sans" style="font-size:14px;padding-top:2em"></span></body></html>