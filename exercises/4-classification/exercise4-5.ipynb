{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification on `emnist`\n",
    "\n",
    "## 1. Create `Readme.md` to document your work\n",
    "\n",
    "Explain your choices, process, and outcomes.\n",
    "\n",
    "## 2. Classify ~~all symbols~~ letters a -> g\n",
    "\n",
    "### Subset the data\n",
    "\n",
    "Select only the lowercase letters (a, b, ..., g) for classification\n",
    "\n",
    "### Choose a model\n",
    "\n",
    "Your choice of model! Choose wisely...\n",
    "\n",
    "### Train away!\n",
    "\n",
    "Is do you need to tune any parameters? Is the model expecting data in a different format?\n",
    "\n",
    "### Evaluate the model\n",
    "\n",
    "Evaluate the models on the test set, analyze the confusion matrix to see where the model performs well and where it struggles.\n",
    "\n",
    "### Investigate subsets\n",
    "\n",
    "On which classes does the model perform well? Poorly? Evaluate again, excluding easily confused symbols (such as 'O' and '0').\n",
    "\n",
    "### Improve performance\n",
    "\n",
    "Brainstorm for improving the performance. This could include trying different architectures, adding more layers, changing the loss function, or using data augmentation techniques.\n",
    "\n",
    "## 3. Model showdown: upper vs lowercase on abcXYZ\n",
    "\n",
    "### Subset the data\n",
    "\n",
    "Select out the set of upper- and lowercase (a, b, c, x, y z, A, B, C, X, Y, Z). Note that some of these classes can be confusing (e.g., x and y).\n",
    "\n",
    "### Train and tune models\n",
    "\n",
    "Perform a full model training and hyperparameter tuning.\n",
    "\n",
    "1. Select candidate models, hyperparameter options, and evaluation metric\n",
    "2. Set aside a validation hold-out dataset\n",
    "3. Train models over K splits (use k-fold or train/test split)\n",
    "    1. Split train using k-fold with the number of folds equal to the number of parameter combinations\n",
    "    2. Train on k-fold split\n",
    "    3. Record performance of each set of parameters\n",
    "    4. Use winning set of parameters to train model on full training set\n",
    "    5. Record each model's performance on that split's test set\n",
    "4. Evaluate model performance and promote one model as the winner\n",
    "5. Train winning model on both train + test\n",
    "6. Check model performance on the validation hold-out\n",
    "\n",
    "\n",
    "## 4. (_Optional_) Model comparison: classify even vs odd\n",
    "\n",
    "**NOTE:** This is a larger dataset (~400k rows) so it will require more memory and time to train models on it. \n",
    "\n",
    "Alternatively, you can train models on smaller subsets of the data to get a feel for which models perform better than others. Then train the winning model on the full dataset and validate against the hold-out.\n",
    "\n",
    "### Subset the data\n",
    "\n",
    "Select only digits and add a column for 'is_even'. Be sure to create a validation hold-out dataset for later.\n",
    "\n",
    "### Build and compare models\n",
    "\n",
    "Train at least two different models, compare the results and choose a winner based on an evaluation metric of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q emnist pandas pyarrow numpy matplotlib seaborn scikit-learn xgboost tensorflow\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\"HI!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import emnist\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# ML packages\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# XGBoost (SVM)\n",
    "from xgboost import XGBClassifier\n",
    "# Deep Learning\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "# Constants\n",
    "SIZE = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper functions\n",
    "def int_to_char(label):\n",
    "    \"\"\"Convert an integer label to the corresponding uppercase character.\"\"\"\n",
    "    if label < 10:\n",
    "        return str(label)\n",
    "    elif label < 36:\n",
    "        return chr(label - 10 + ord('A'))\n",
    "    else:\n",
    "        return chr(label - 36 + ord('a'))\n",
    "\n",
    "def show_image(row):\n",
    "    \"\"\"Display a single image and its corresponding label.\"\"\"\n",
    "    image = row['image']\n",
    "    label = row['label']\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title('Label: ' + int_to_char(label))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def show_grid(data, title=None, num_cols=5, figsize=(20, 10)):\n",
    "    \"\"\"\n",
    "    Display a list of images as a grid of num_cols columns.\n",
    "    images: a list of images, each represented as a 28x28 numpy array\n",
    "    labels: a list of labels, one for each image\n",
    "    title: (optional) a title for the plot\n",
    "    num_cols: (optional) number of columns to use in the grid\n",
    "    figsize: (optional) size of the figure\n",
    "    \"\"\"\n",
    "    num_images = len(data)\n",
    "    num_rows = (num_images - 1) // num_cols + 1\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "    if title is not None:\n",
    "        fig.suptitle(title, fontsize=16)\n",
    "    for i in range(num_rows):\n",
    "        for j in range(num_cols):\n",
    "            index = i * num_cols + j\n",
    "            if index < num_images:\n",
    "                axes[i, j].imshow(data.iloc[index]['image'], cmap='gray')\n",
    "                axes[i, j].axis('off')\n",
    "                label = int_to_char(data.iloc[index]['label'])\n",
    "                axes[i, j].set_title(label)\n",
    "    plt.show()\n",
    "\n",
    "# Get a random image of a given label from the dataset\n",
    "def get_image_by_label(data, label):\n",
    "    \"\"\"Get a random image of a given label from the dataset.\"\"\"\n",
    "    images = data[data['label'] == label]['image'].tolist()\n",
    "    return random.choice(images)\n",
    "\n",
    "# Plot the training and validation accuracy during the training of a model\n",
    "def plot_accuracy(history):\n",
    "    \"\"\"Plot the training and validation accuracy during the training of a model.\"\"\"\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the training and validation loss during the training of a model\n",
    "def plot_loss(history):\n",
    "    \"\"\"Plot the training and validation loss during the training of a model.\"\"\"\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Normalize the pixel values of the images in the dataset to have zero mean and unit variance\n",
    "# This is a common preprocessing step for neural networks, but may not be necessary in all cases\n",
    "def normalize_images(images):\n",
    "    \"\"\"Normalize the pixel values of the images in the dataset to have zero mean and unit variance.\"\"\"\n",
    "    images = np.array(images)\n",
    "    mean = images.mean()\n",
    "    std = images.std()\n",
    "    images = (images - mean) / std\n",
    "    return images.tolist()\n",
    "\n",
    "# Display metrics for a model\n",
    "def display_metrics(task, model_name, metrics_dict):\n",
    "    \"\"\"Display performance metrics and confusion matrix for a model.\"\"\"\n",
    "    metrics_df = pd.DataFrame()\n",
    "    cm_df = pd.DataFrame()\n",
    "    for key, value in metrics_dict[task][model_name].items():\n",
    "        if type(value) == np.ndarray:\n",
    "            cm_df = pd.DataFrame(value, index=['actual a', 'actual b','actual c','actual d','actual e','actual f','actual g'], columns=['predicted a', 'predicted b','predicted c','predicted d','predicted e','predicted f','predicted g'])\n",
    "        else:\n",
    "            metrics_df[key] = [value]\n",
    "    display(Markdown(f'# Performance Metrics: {model_name}'))\n",
    "    display(metrics_df)\n",
    "    display(Markdown(f'# Confusion Matrix: {model_name}'))\n",
    "    display(cm_df)\n",
    "\n",
    "def display_metrics2(task, model_name, metrics_dict):\n",
    "    \"\"\"Display performance metrics and confusion matrix for a model.\"\"\"\n",
    "    metrics_df = pd.DataFrame()\n",
    "    cm_df = pd.DataFrame()\n",
    "    for key, value in metrics_dict[task][model_name].items():\n",
    "        if type(value) == np.ndarray:\n",
    "            cm_df = pd.DataFrame(value, index=['actual a', 'actual b','actual c','actual A','actual B','actual C','actual x','actual y','actual z','actual X','actual Y','actual Z'], columns=['predicted a', 'predicted b','predicted c','predicted A','predicted B','predicted C','predicted x','predicted y','predicted z','predicted X','predicted Y','predicted Z'])\n",
    "        else:\n",
    "            metrics_df[key] = [value]\n",
    "    display(Markdown(f'# Performance Metrics: {model_name}'))\n",
    "    display(metrics_df)\n",
    "    display(Markdown(f'# Confusion Matrix: {model_name}'))\n",
    "    display(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'emnist_all'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "# Extract the training split as images and labels\n",
    "image, label = emnist.extract_training_samples('byclass')\n",
    "\n",
    "# Add columns for each pixel value (28x28 = 784 columns)\n",
    "emnist_train = pd.DataFrame()\n",
    "\n",
    "# Add a column with the image data as a 28x28 array\n",
    "emnist_train['image'] = list(image)\n",
    "emnist_train['image_flat'] = emnist_train['image'].apply(lambda x: np.array(x).reshape(-1))\n",
    "\n",
    "# Add a column showing the label\n",
    "emnist_train['label'] = label\n",
    "\n",
    "# Convert labels to characters\n",
    "class_label = np.array([int_to_char(l) for l in label])\n",
    "\n",
    "# Add a column with the character corresponding to the label\n",
    "emnist_train['class'] = class_label\n",
    "\n",
    "# Repeat for the test split\n",
    "image, label = emnist.extract_test_samples('byclass')\n",
    "class_label = np.array([int_to_char(l) for l in label])\n",
    "emnist_test = pd.DataFrame()\n",
    "emnist_test['image'] = list(image)\n",
    "emnist_test['image_flat'] = emnist_test['image'].apply(lambda x: np.array(x).reshape(-1))\n",
    "emnist_test['label'] = label\n",
    "emnist_test['class'] = class_label\n",
    "\n",
    "\n",
    "# Combine the training and test splits\n",
    "emnist_all = pd.concat([emnist_train, emnist_test], axis=0)\n",
    "display('emnist_all')\n",
    "# Subset for only digits 0-9\n",
    "digits = emnist_all[emnist_all['label'] < 10]\n",
    "\n",
    "# Subset for lowercase letters\n",
    "lowercase = emnist_all[(emnist_all['class'] >= 'a') & (emnist_all['class'] <= 'z')]\n",
    "uppercase = emnist_all[(emnist_all['class'] >= 'A') & (emnist_all['class'] <= 'Z')]\n",
    "\n",
    "# Subset for upper- and lowercase letters a, b, c, d, e, f, g\n",
    "a2g = emnist_all[(emnist_all['class'].isin(['a', 'b', 'c', 'd', 'e', 'f', 'g']))]\n",
    "\n",
    "# Subset for upper- and lowercase letters a, b, c, x, y, z\n",
    "abcxyz = emnist_all[(emnist_all['class'].isin(['a', 'b', 'c', 'A', 'B', 'C', \\\n",
    "                                               'x', 'y', 'z', 'X', 'Y', 'Z']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the size of a2g, abcxyz, digits, and the full dataset\n",
    "display(Markdown(f'# Dataset Sizes'))\n",
    "display(Markdown(f'**a2g**: {len(a2g)}'))\n",
    "display(Markdown(f'**abcxyz**: {len(abcxyz)}'))\n",
    "display(Markdown(f'**digits**: {len(digits)}'))\n",
    "display(Markdown(f'**emnist_all**: {len(emnist_all)}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: Classify lettters as uppercase/lowercase\n",
    "abcxyz['is_upper'] = abcxyz['class'].apply(lambda x: x.isupper())\n",
    "abcxyz['is_lower'] = abcxyz['class'].apply(lambda x: x.islower())\n",
    "\n",
    "# FIXME: Classify digits as even/odd\n",
    "digits['is_even'] = digits['label'] % 2 == 0\n",
    "digits['is_odd'] = digits['label'] % 2 != 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols_list = ['a', 'b', 'c', 'd', 'e', 'f', 'g']\n",
    "\n",
    "mask_train = emnist_train['class'].apply(lambda x: x in symbols_list)\n",
    "train_01 = emnist_train[mask_train]\n",
    "train_01.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mask_valid = emnist_test['class'].apply(lambda x: x in symbols_list)\n",
    "valid_01 = emnist_test[mask_valid]\n",
    "valid_01.reset_index(drop=True, inplace=True)\n",
    "\n",
    "metrics_dict = {\n",
    "    'a2g' : { # task name (a2g classifier)\n",
    "        'logistic_regression': {\n",
    "            'confusion_matrix': [],\n",
    "            'accuracy': [],\n",
    "            'precision': [],\n",
    "            'recall': [],\n",
    "            'f1': []\n",
    "        },\n",
    "        'xgboost': {\n",
    "            'confusion_matrix': [],\n",
    "            'accuracy': [],\n",
    "            'precision': [],\n",
    "            'recall': [],\n",
    "            'f1': []\n",
    "        },\n",
    "        'random_forest': {\n",
    "            'confusion_matrix': [],\n",
    "            'accuracy': [],\n",
    "            'precision': [],\n",
    "            'recall': [],\n",
    "            'f1': []\n",
    "        },\n",
    "        'neural_network': {\n",
    "            'confusion_matrix': [],\n",
    "            'accuracy': [],\n",
    "            'precision': [],\n",
    "            'recall': [],\n",
    "            'f1': []\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "task = 'a2g'\n",
    "model_name = 'random_forest'\n",
    "metrics_dict[task] = {model_name: {}}\n",
    "\n",
    "# Initialize random forest classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train and evaluate model\n",
    "rf_clf.fit(train_01['image_flat'].tolist(), train_01['label'])\n",
    "y_pred = rf_clf.predict(valid_01['image_flat'].tolist())\n",
    "\n",
    "acc = accuracy_score(valid_01['label'], y_pred)\n",
    "prec = precision_score(valid_01['label'], y_pred, average='micro')\n",
    "rec = recall_score(valid_01['label'], y_pred, average='micro')\n",
    "f1 = f1_score(valid_01['label'], y_pred, average='micro')\n",
    "cm = confusion_matrix(valid_01['label'], y_pred)\n",
    "\n",
    "# Store performance metrics in dictionary\n",
    "metrics_dict[task][model_name] = {'accuracy': acc,\n",
    "                                  'precision': prec,\n",
    "                                  'recall': rec,\n",
    "                                  'f1': f1,\n",
    "                                  'confusion_matrix': cm}\n",
    "\n",
    "# Display performance metrics\n",
    "display_metrics(task, model_name, metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Exclude easily confused symbols\n",
    "excluded_symbols = ['O', '0']\n",
    "\n",
    "# Filter the data to exclude easily confused symbols\n",
    "valid_filtered = valid_01[~valid_01['class'].isin(excluded_symbols)]\n",
    "\n",
    "# Predict labels for the filtered data\n",
    "y_pred_filtered = rf_clf.predict(valid_filtered['image_flat'].tolist())\n",
    "\n",
    "# Calculate performance metrics for each class\n",
    "performance_metrics = {}\n",
    "for symbol in symbols_list:\n",
    "    if symbol not in excluded_symbols:\n",
    "        symbol_indices = valid_filtered['class'] == symbol\n",
    "        symbol_labels = valid_filtered.loc[symbol_indices, 'label']\n",
    "        symbol_predictions = y_pred_filtered[symbol_indices]\n",
    "        accuracy = accuracy_score(symbol_labels, symbol_predictions)\n",
    "        precision = precision_score(symbol_labels, symbol_predictions, average='micro')\n",
    "        recall = recall_score(symbol_labels, symbol_predictions, average='micro')\n",
    "        f1 = f1_score(symbol_labels, symbol_predictions, average='micro')\n",
    "        performance_metrics[symbol] = {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1}\n",
    "\n",
    "# Sort the performance metrics by accuracy in descending order\n",
    "sorted_metrics = sorted(performance_metrics.items(), key=lambda x: x[1]['accuracy'], reverse=True)\n",
    "\n",
    "# Display the performance metrics\n",
    "for symbol, metrics in sorted_metrics:\n",
    "    print(f\"Symbol: {symbol}\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']}\")\n",
    "    print(f\"Precision: {metrics['precision']}\")\n",
    "    print(f\"Recall: {metrics['recall']}\")\n",
    "    print(f\"F1 Score: {metrics['f1']}\")\n",
    "    print(\"--------------------\")\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm_filtered = confusion_matrix(valid_filtered['label'], y_pred_filtered)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_filtered, annot=True, fmt='d', cmap='Blues', xticklabels=symbols_list, yticklabels=symbols_list)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix (Excluding Easily Confused Symbols)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Performance Metrics: xgboost"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.84009</td>\n",
       "      <td>0.823308</td>\n",
       "      <td>0.84009</td>\n",
       "      <td>0.827306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision   recall        f1\n",
       "0   0.84009   0.823308  0.84009  0.827306"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Confusion Matrix: xgboost"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted a</th>\n",
       "      <th>predicted b</th>\n",
       "      <th>predicted c</th>\n",
       "      <th>predicted A</th>\n",
       "      <th>predicted B</th>\n",
       "      <th>predicted C</th>\n",
       "      <th>predicted x</th>\n",
       "      <th>predicted y</th>\n",
       "      <th>predicted z</th>\n",
       "      <th>predicted X</th>\n",
       "      <th>predicted Y</th>\n",
       "      <th>predicted Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual a</th>\n",
       "      <td>1032</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual b</th>\n",
       "      <td>7</td>\n",
       "      <td>614</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual c</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1632</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual A</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>297</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual B</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>677</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual C</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>354</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual x</th>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1588</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual y</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>822</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual z</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>376</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual X</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual Y</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual Z</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>119</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted a  predicted b  predicted c  predicted A  predicted B  \\\n",
       "actual a         1032            4            0            4            4   \n",
       "actual b            7          614            4            0            0   \n",
       "actual c            2            0         1632            0            0   \n",
       "actual A            2            0            5          297           14   \n",
       "actual B            1            1            3            3          677   \n",
       "actual C            2            4            0            2            0   \n",
       "actual x           28            8            6            0            2   \n",
       "actual y            1           20            2            1            1   \n",
       "actual z            0            1          376            1            0   \n",
       "actual X            6            0            1          119            5   \n",
       "actual Y            3            1            0            1          173   \n",
       "actual Z            2            3            4            1            3   \n",
       "\n",
       "          predicted C  predicted x  predicted y  predicted z  predicted X  \\\n",
       "actual a            0           17            0            0            1   \n",
       "actual b            3           11            6            1            0   \n",
       "actual c            3           13            1           84            3   \n",
       "actual A            1            1            1            0          107   \n",
       "actual B            0            6            0            0            5   \n",
       "actual C          354            2            0            0            1   \n",
       "actual x            0         1588            2            1            1   \n",
       "actual y            1            3          822            0            1   \n",
       "actual z            0            6            2           45            1   \n",
       "actual X            0            5            0            0          320   \n",
       "actual Y            0            5            0            0            4   \n",
       "actual Z          119            9            2            1            2   \n",
       "\n",
       "          predicted Y  predicted Z  \n",
       "actual a            0            0  \n",
       "actual b            0            2  \n",
       "actual c            0            1  \n",
       "actual A            2            2  \n",
       "actual B           99            3  \n",
       "actual C            0           99  \n",
       "actual x            2            6  \n",
       "actual y            1            0  \n",
       "actual z            0            0  \n",
       "actual X            8            6  \n",
       "actual Y          194            0  \n",
       "actual Z            5          300  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Perform a full model training and hyperparameter tuning.\n",
    "\n",
    "# 1. Select candidate models, hyperparameter options, and evaluation metric\n",
    "# 2. Set aside a validation hold-out dataset\n",
    "\n",
    "# abcxyz = emnist_all[(emnist_all['class'].isin(['a', 'b', 'c', 'A', 'B', 'C', 'x', 'y', 'z', 'X', 'Y', 'Z']))]\n",
    "# abcxyz Classifier: XGBoost\n",
    "task = 'abcxyz'\n",
    "model_name = 'xgboost'\n",
    "metrics_dict2 = {\n",
    "    'abcxyz' : { # task name (abcxyz classifier)\n",
    "        'logistic_regression': {\n",
    "            'confusion_matrix': [],\n",
    "            'accuracy': [],\n",
    "            'precision': [],\n",
    "            'recall': [],\n",
    "            'f1': []\n",
    "        },\n",
    "        'xgboost': {\n",
    "            'confusion_matrix': [],\n",
    "            'accuracy': [],\n",
    "            'precision': [],\n",
    "            'recall': [],\n",
    "            'f1': []\n",
    "        },\n",
    "        'random_forest': {\n",
    "            'confusion_matrix': [],\n",
    "            'accuracy': [],\n",
    "            'precision': [],\n",
    "            'recall': [],\n",
    "            'f1': []\n",
    "        },\n",
    "        'neural_network': {\n",
    "            'confusion_matrix': [],\n",
    "            'accuracy': [],\n",
    "            'precision': [],\n",
    "            'recall': [],\n",
    "            'f1': []\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "symbols_list2 = ['a', 'b', 'c', 'A', 'B', 'C', 'x', 'y', 'z', 'X', 'Y', 'Z']\n",
    "\n",
    "mask_train2 = emnist_train['class'].apply(lambda x: x in symbols_list2)\n",
    "label_mapping = {10: 0, 11: 1, 12: 2, 33: 3, 34: 4, 35: 5, 36: 6, 37: 7, 38: 8, 59: 9, 60: 10, 61: 11}\n",
    "emnist_train['label'] = emnist_train['label'].map(label_mapping)\n",
    "train_02 = emnist_train[mask_train2]\n",
    "train_02.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mask_valid2 = emnist_test['class'].apply(lambda x: x in symbols_list2)\n",
    "emnist_test['label'] = emnist_test['label'].map(label_mapping)\n",
    "valid_02 = emnist_test[mask_valid2]\n",
    "valid_02.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Initialize XGBoost classifier\n",
    "xgb_clf = XGBClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train and evaluate model\n",
    "xgb_clf.fit(train_02['image_flat'].tolist(), train_02['label'])\n",
    "y_pred = xgb_clf.predict(valid_02['image_flat'].tolist())\n",
    "\n",
    "# Calculate performance metrics\n",
    "acc = accuracy_score(valid_02['label'], y_pred)\n",
    "prec = precision_score(valid_02['label'], y_pred, average='weighted')\n",
    "rec = recall_score(valid_02['label'], y_pred, average='weighted')\n",
    "f1 = f1_score(valid_02['label'], y_pred, average='weighted')\n",
    "cm = confusion_matrix(valid_02['label'], y_pred)\n",
    "\n",
    "# Store performance metrics in dictionary\n",
    "metrics_dict2[task][model_name] = {'accuracy': acc,\n",
    "                                  'precision': prec,\n",
    "                                  'recall': rec,\n",
    "                                  'f1': f1,\n",
    "                                  'confusion_matrix': cm}\n",
    "\n",
    "# Display performance metrics\n",
    "display_metrics2(task, model_name, metrics_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1x/w1hxfg6x5jj6vc7_6lpq5hjc0000gn/T/ipykernel_33775/317069213.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  abcxyz['class'] = abcxyz['class'].map(label_mapping2)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m        model\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparam_combination)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# cross_val_score returns array of scores, which you need to take the avg\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m        scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m        avg_score \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(scores)\n\u001b[1;32m     31\u001b[0m        \u001b[38;5;28;01mif\u001b[39;00m avg_score \u001b[38;5;241m>\u001b[39m best_score:\n",
      "File \u001b[0;32m~/Desktop/study/UCSF/datasci 223 python/datasci_223/.conda/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/study/UCSF/datasci 223 python/datasci_223/.conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:719\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    717\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 719\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/study/UCSF/datasci 223 python/datasci_223/.conda/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/study/UCSF/datasci 223 python/datasci_223/.conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:430\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 430\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/study/UCSF/datasci 223 python/datasci_223/.conda/lib/python3.11/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/study/UCSF/datasci 223 python/datasci_223/.conda/lib/python3.11/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/Desktop/study/UCSF/datasci 223 python/datasci_223/.conda/lib/python3.11/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/Desktop/study/UCSF/datasci 223 python/datasci_223/.conda/lib/python3.11/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/study/UCSF/datasci 223 python/datasci_223/.conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:895\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    893\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 895\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    899\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/Desktop/study/UCSF/datasci 223 python/datasci_223/.conda/lib/python3.11/site-packages/xgboost/core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/study/UCSF/datasci 223 python/datasci_223/.conda/lib/python3.11/site-packages/xgboost/sklearn.py:1519\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1491\u001b[0m (\n\u001b[1;32m   1492\u001b[0m     model,\n\u001b[1;32m   1493\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1498\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1499\u001b[0m )\n\u001b[1;32m   1500\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1501\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1502\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1517\u001b[0m )\n\u001b[0;32m-> 1519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/study/UCSF/datasci 223 python/datasci_223/.conda/lib/python3.11/site-packages/xgboost/core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/study/UCSF/datasci 223 python/datasci_223/.conda/lib/python3.11/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/study/UCSF/datasci 223 python/datasci_223/.conda/lib/python3.11/site-packages/xgboost/core.py:2051\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2047\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2050\u001b[0m     _check_call(\n\u001b[0;32m-> 2051\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2052\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2054\u001b[0m     )\n\u001b[1;32m   2055\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2056\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold, ParameterGrid, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "label_mapping2 = {\"A\": 0, \"B\": 1, \"C\": 2, \"X\": 3, \"Y\": 4, \"Z\": 5, \"a\": 6, \"b\": 7, \"c\": 8, \"x\": 9, \"y\": 10, \"z\": 11}\n",
    "abcxyz['class'] = abcxyz['class'].map(label_mapping2)\n",
    "X=abcxyz['image_flat'].tolist()\n",
    "y=abcxyz['class'].tolist()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "best_score = 0\n",
    "best_model = None\n",
    "rf_param_grid = {'n_estimators': [50, 100, 150], 'max_depth': [None, 10, 20]}\n",
    "xgb_param_grid = {'n_estimators': [50, 100, 150], 'max_depth': [3, 5, 7], 'learning_rate': [0.01, 0.1, 0.2]}\n",
    "scoring_metric = 'accuracy'\n",
    "models = [\n",
    "    (RandomForestClassifier(), rf_param_grid),\n",
    "    (XGBClassifier(), xgb_param_grid)\n",
    "]\n",
    "# If you want to use cross_val_score instead of doing above manually\n",
    "\t\t# Using sklearn's function.\n",
    "for model, param_grid in models:\n",
    "    for param_combination in ParameterGrid(param_grid):\n",
    "        model.set_params(**param_combination)\n",
    " # cross_val_score returns array of scores, which you need to take the avg\n",
    "        scores = cross_val_score(model, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "        avg_score = np.mean(scores)\n",
    "        if avg_score > best_score:\n",
    "            best_score = avg_score\n",
    "    best_model = model \n",
    "\n",
    "\n",
    "print(f\"Best Model Parameters: {best_model}\")\n",
    "print(f\"Best Model Average Cross-Validation Score: {best_score}\")\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_val_pred = best_model.predict(X_val)\n",
    "validation_score = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Validation Hold-out Score: {validation_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision  # \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
